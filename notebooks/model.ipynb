{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d00bf5-6422-40c9-b6e7-e3d27b35a3aa",
   "metadata": {},
   "source": [
    "## Cell 1: Import Libraries and Load Initial Data\n",
    "This cell imports necessary libraries and loads your train.csv dataset into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d7ec94-e17c-4fb2-a3b6-237dfead7d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data loaded.\n",
      "Shape of train_df: (159571, 8)\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "print(\"Initial data loaded.\")\n",
    "print(f\"Shape of train_df: {train_df.shape}\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fc1c5-25fb-4bc2-b9f1-52492cc57a3b",
   "metadata": {},
   "source": [
    "### Cell 2: Define Text Preprocessing Function \n",
    "This cell defines your custom text preprocessing function using spaCy and regular expressions. It also loads the spaCy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1018dd39-0b6c-4fc8-a299-69954f115e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy 'en_core_web_sm' model loaded for preprocessing.\n",
      "Custom text preprocessing function 'preprocess_text_custom_spacy' defined.\n"
     ]
    }
   ],
   "source": [
    "nlp_preprocessor = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "print(\"spaCy 'en_core_web_sm' model loaded for preprocessing.\")\n",
    "\n",
    "def preprocess_text_custom_spacy(text_to_process, nlp_instance):\n",
    "    if not nlp_instance:\n",
    "        pass \n",
    "    if not isinstance(text_to_process, str): text_to_process = str(text_to_process)\n",
    "    \n",
    "    text_to_process = text_to_process.lower()\n",
    "    text_to_process = re.sub(r'https?://\\S+|www\\.\\S+', '', text_to_process)\n",
    "    text_to_process = re.sub(r'@\\w+', '', text_to_process)\n",
    "    text_to_process = re.sub(r'<.*?>', '', text_to_process)\n",
    "    text_to_process = re.sub(r'[^a-z\\s]', '', text_to_process)\n",
    "    text_to_process = re.sub(r'\\s+', ' ', text_to_process).strip()\n",
    "    \n",
    "    doc = nlp_instance(text_to_process)\n",
    "    processed_tokens = [\n",
    "        token.lemma_ for token in doc if token.is_alpha and not token.is_stop\n",
    "    ]\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "print(\"Custom text preprocessing function 'preprocess_text_custom_spacy' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982fb27-c85b-4c3c-812e-a53364532d85",
   "metadata": {},
   "source": [
    "### Cell 3: Apply Text Preprocessing\n",
    "This cell applies the defined preprocessing function to your comment text, handles NaNs, and removes any rows that become empty after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2f834b-bf2d-4897-a8b2-77da33b87a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing applied. Rows after processing and removing empty: 159434 (removed 137)\n",
      "                                        comment_text  \\\n",
      "0  Explanation\\nWhy the edits made under my usern...   \n",
      "1  D'aww! He matches this background colour I'm s...   \n",
      "2  Hey man, I'm really not trying to edit war. It...   \n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
      "4  You, sir, are my hero. Any chance you remember...   \n",
      "\n",
      "                              comment_text_processed  \n",
      "0  explanation edit username hardcore metallica f...  \n",
      "1  daww match background colour m seemingly stick...  \n",
      "2  hey man m try edit war guy constantly remove r...  \n",
      "3  not real suggestion improvement wonder section...  \n",
      "4                    sir hero chance remember page s  \n"
     ]
    }
   ],
   "source": [
    "train_df_processed = train_df.copy()\n",
    "train_df_processed['comment_text_processed'] = train_df_processed['comment_text'].fillna('').apply(\n",
    "    lambda x: preprocess_text_custom_spacy(x, nlp_preprocessor)\n",
    ")\n",
    "\n",
    "initial_rows = train_df_processed.shape[0]\n",
    "train_df_processed = train_df_processed[train_df_processed['comment_text_processed'] != \"\"]\n",
    "rows_removed = initial_rows - train_df_processed.shape[0]\n",
    "\n",
    "print(f\"Text preprocessing applied. Rows after processing and removing empty: {train_df_processed.shape[0]} (removed {rows_removed})\")\n",
    "print(train_df_processed[['comment_text', 'comment_text_processed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3588e9-e379-4022-9b7f-1e56a8389f78",
   "metadata": {},
   "source": [
    "### Cell 4: Build Vocabulary, Numericalize, and Pad Sequences\n",
    "This cell creates the vocabulary from the processed text, converts text to numerical sequences, and pads/truncates them to a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a70387a-4a18-4976-bb21-eafef7f629b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary created (size: 197521), SEQ_LENGTH set to 200.\n",
      "Column 'padded_features' created.\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_TEXT_COLUMN_NAME = 'comment_text_processed'\n",
    "\n",
    "all_processed_words = [word for comment in train_df_processed[PROCESSED_TEXT_COLUMN_NAME].astype(str) for word in comment.split()]\n",
    "word_counts = Counter(all_processed_words)\n",
    "sorted_words = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "vocab_to_int = {word: i+2 for i, word in enumerate(sorted_words)}\n",
    "vocab_to_int['<pad>'] = 0\n",
    "vocab_to_int['<unk>'] = 1\n",
    "SEQ_LENGTH = 200\n",
    "\n",
    "train_df_processed['padded_features'] = train_df_processed[PROCESSED_TEXT_COLUMN_NAME].apply(\n",
    "    lambda text: (\n",
    "        lambda seq: seq[:SEQ_LENGTH] if len(seq) > SEQ_LENGTH else seq + [vocab_to_int['<pad>']] * (SEQ_LENGTH - len(seq))\n",
    "    )([vocab_to_int.get(word, vocab_to_int['<unk>']) for word in str(text).split() if word])\n",
    ")\n",
    "\n",
    "print(f\"Vocabulary created (size: {len(vocab_to_int)}), SEQ_LENGTH set to {SEQ_LENGTH}.\")\n",
    "print(\"Column 'padded_features' created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c6530-4d29-41ca-9b93-742eefcd0e11",
   "metadata": {},
   "source": [
    "### Cell 5: Prepare PyTorch Tensors, Dataset, and DataLoaders\n",
    "This cell extracts the padded features and labels, converts them to PyTorch tensors, defines a custom Dataset class, splits data into training and validation sets, and creates DataLoader instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f10b2fc-dacc-490d-92dc-d2ede915e64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features_tensor: torch.Size([159434, 200])\n",
      "Shape of labels_tensor: torch.Size([159434, 6])\n",
      "Training samples: 127548, Validation samples: 31886\n",
      "DataLoaders will be configured for device: mps\n",
      "PyTorch Dataset and DataLoaders created.\n"
     ]
    }
   ],
   "source": [
    "X_list = train_df_processed['padded_features'].tolist()\n",
    "X_np = np.array(X_list, dtype=np.int64)\n",
    "features_tensor = torch.from_numpy(X_np)\n",
    "\n",
    "label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y_np = train_df_processed[label_columns].values.astype(np.float32)\n",
    "labels_tensor = torch.from_numpy(y_np)\n",
    "\n",
    "print(f\"Shape of features_tensor: {features_tensor.shape}\")\n",
    "print(f\"Shape of labels_tensor: {labels_tensor.shape}\")\n",
    "\n",
    "class ToxicityDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "full_dataset = ToxicityDataset(features_tensor, labels_tensor)\n",
    "\n",
    "validation_split = 0.2\n",
    "dataset_size = len(full_dataset)\n",
    "val_size = int(validation_split * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0 \n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"DataLoaders will be configured for device: {device}\")\n",
    "use_pin_memory = True if device.type != 'cpu' else False\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=NUM_WORKERS, pin_memory=use_pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=use_pin_memory)\n",
    "\n",
    "print(\"PyTorch Dataset and DataLoaders created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875e6cf-5656-43b8-80cc-79b217553ef1",
   "metadata": {},
   "source": [
    "### Cell 6: Define NBoW Model, Loss, and Optimizer\n",
    "This cell defines the SimplerNBoWClassifier model class, sets up the device, instantiates the model, defines the loss function (BCEWithLogitsLoss without weights for this baseline), and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b5e55e-3936-4658-870f-57f3079e7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBoW Model, Loss function, and Optimizer defined.\n",
      "Model moved to device: mps\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE_NBOW = len(vocab_to_int)\n",
    "EMBEDDING_DIM_NBOW = 100 \n",
    "OUTPUT_DIM_NBOW = 6      \n",
    "padding_idx_nbow = vocab_to_int.get('<pad>', 0)\n",
    "\n",
    "class SimplerNBoWClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, padding_idx_val):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx_val)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, text_batch):\n",
    "        embedded = self.embedding(text_batch)\n",
    "        averaged_embeddings = torch.mean(embedded, dim=1)\n",
    "        logits = self.fc(averaged_embeddings)\n",
    "        return logits\n",
    "\n",
    "model_nbow = SimplerNBoWClassifier(VOCAB_SIZE_NBOW, EMBEDDING_DIM_NBOW, OUTPUT_DIM_NBOW, padding_idx_nbow)\n",
    "model_nbow.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "LEARNING_RATE_NBOW = 0.001\n",
    "optimizer_nbow = optim.Adam(model_nbow.parameters(), lr=LEARNING_RATE_NBOW)\n",
    "\n",
    "print(\"NBoW Model, Loss function, and Optimizer defined.\")\n",
    "print(f\"Model moved to device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c6d24-4fe3-4660-a5f8-66c3cb7983a4",
   "metadata": {},
   "source": [
    "### Cell 7: Helper Functions for Training and Evaluation Epochs\n",
    "Defines two helper functions: `train_epoch_func` for handling the logic of a single training epoch (forward pass, loss calculation, backpropagation, optimizer step) and `evaluate_epoch_func` for a single validation epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c086156e-fcc7-43df-9f07-d2d621302bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions 'train_epoch_func' and 'evaluate_epoch_func' defined.\n"
     ]
    }
   ],
   "source": [
    "def train_epoch_func(model, dataloader, criterion_fn, optimizer_fn, current_device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for features, labels in dataloader:\n",
    "        features = features.to(current_device)\n",
    "        labels = labels.to(current_device)\n",
    "        optimizer_fn.zero_grad()\n",
    "        predictions = model(features)\n",
    "        loss = criterion_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer_fn.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_epoch_func(model, dataloader, criterion_fn, current_device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            features = features.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            predictions = model(features)\n",
    "            loss = criterion_fn(predictions, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "print(\"Helper functions 'train_epoch_func' and 'evaluate_epoch_func' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f887c26-85fa-4db8-b276-5006503c1527",
   "metadata": {},
   "source": [
    "## Cell 8: Calculate Class Weights and Define Weighted Loss Function\n",
    "Calculates positive class weights (`pos_weight`) for each toxicity category based on the training set distribution to address class imbalance. Defines a new `BCEWithLogitsLoss` criterion (`criterion_nbow_weighted`) using these calculated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c01ef64-5ed4-4924-a19b-3b95496ead21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating positive weights for BCEWithLogitsLoss:\n",
      "  Class 'toxic': num_pos=12280.0, num_neg=115268.0, calculated_pos_weight=9.39\n",
      "  Class 'severe_toxic': num_pos=1282.0, num_neg=126266.0, calculated_pos_weight=98.49\n",
      "  Class 'obscene': num_pos=6823.0, num_neg=120725.0, calculated_pos_weight=17.69\n",
      "  Class 'threat': num_pos=379.0, num_neg=127169.0, calculated_pos_weight=335.54\n",
      "  Class 'insult': num_pos=6357.0, num_neg=121191.0, calculated_pos_weight=19.06\n",
      "  Class 'identity_hate': num_pos=1138.0, num_neg=126410.0, calculated_pos_weight=111.08\n",
      "\n",
      "pos_weights_tensor created and moved to device.\n",
      "tensor([  9.3866,  98.4914,  17.6938, 335.5383,  19.0642, 111.0808],\n",
      "       device='mps:0')\n",
      "\n",
      "Weighted BCEWithLogitsLoss ('criterion_nbow_weighted') defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_labels_np = labels_tensor[train_dataset.indices].cpu().numpy() \n",
    "\n",
    "pos_weights_list = []\n",
    "print(\"Calculating positive weights for BCEWithLogitsLoss:\")\n",
    "for i, col_name in enumerate(label_columns):\n",
    "    num_total_train_samples = train_labels_np.shape[0]\n",
    "    num_pos = train_labels_np[:, i].sum()\n",
    "    num_neg = num_total_train_samples - num_pos\n",
    "\n",
    "    if num_pos > 0 and num_neg > 0:\n",
    "        weight = num_neg / num_pos\n",
    "    elif num_pos == 0 and num_neg > 0: \n",
    "        weight = num_total_train_samples \n",
    "        print(f\"Warning: No positive samples found for class '{col_name}' in training data. Using large weight: {weight:.2f}\")\n",
    "    else: \n",
    "        weight = 1.0 \n",
    "        print(f\"Warning: No negative samples or no samples for class '{col_name}'? Using weight: {weight:.2f}\")\n",
    "        \n",
    "    pos_weights_list.append(weight)\n",
    "    print(f\"  Class '{col_name}': num_pos={num_pos}, num_neg={num_neg}, calculated_pos_weight={weight:.2f}\")\n",
    "\n",
    "pos_weights_tensor = torch.tensor(pos_weights_list, dtype=torch.float32).to(device)\n",
    "print(\"\\npos_weights_tensor created and moved to device.\")\n",
    "print(pos_weights_tensor)\n",
    "\n",
    "criterion_nbow_weighted = nn.BCEWithLogitsLoss(pos_weight=pos_weights_tensor)\n",
    "print(\"\\nWeighted BCEWithLogitsLoss ('criterion_nbow_weighted') defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c506a-4d9f-4504-9bf1-889f0a43f460",
   "metadata": {},
   "source": [
    "### Cell 9: NBoW Model Training Loop (with Weighted Loss)\n",
    "Executes the main training loop for the NBoW model (`model_nbow`) for a specified number of epochs. This loop uses the `train_epoch_func`, `evaluate_epoch_func`, the NBoW optimizer, and the `criterion_nbow_weighted` (weighted loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9d7fac-b795-4e0d-b45d-8f336fdd2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NBoW model training for 10 epochs...\n",
      "Epoch [1/10] (NBoW) - Train Loss: 1.0911, Val Loss: 0.8907, Duration: 172.11s\n",
      "Epoch [2/10] (NBoW) - Train Loss: 0.7660, Val Loss: 0.7242, Duration: 161.23s\n",
      "Epoch [3/10] (NBoW) - Train Loss: 0.6169, Val Loss: 0.6802, Duration: 161.79s\n",
      "Epoch [4/10] (NBoW) - Train Loss: 0.5379, Val Loss: 0.6630, Duration: 155.48s\n",
      "Epoch [5/10] (NBoW) - Train Loss: 0.4857, Val Loss: 0.6536, Duration: 158.95s\n",
      "Epoch [6/10] (NBoW) - Train Loss: 0.4433, Val Loss: 0.6495, Duration: 161.01s\n",
      "Epoch [7/10] (NBoW) - Train Loss: 0.4080, Val Loss: 0.6775, Duration: 160.94s\n",
      "Epoch [8/10] (NBoW) - Train Loss: 0.3768, Val Loss: 0.7067, Duration: 154.91s\n",
      "Epoch [9/10] (NBoW) - Train Loss: 0.3485, Val Loss: 0.7069, Duration: 153.63s\n",
      "Epoch [10/10] (NBoW) - Train Loss: 0.3238, Val Loss: 0.7275, Duration: 151.61s\n",
      "\n",
      "NBoW Training finished.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS_NBOW = 10 \n",
    "\n",
    "print(f\"Starting NBoW model training for {NUM_EPOCHS_NBOW} epochs...\")\n",
    "for epoch in range(NUM_EPOCHS_NBOW):\n",
    "    epoch_start_time = time.time()\n",
    "    avg_train_loss = train_epoch_func(model_nbow, train_loader, criterion_nbow_weighted, optimizer_nbow, device)\n",
    "    avg_val_loss = evaluate_epoch_func(model_nbow, val_loader, criterion_nbow_weighted, device)\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS_NBOW}] (NBoW) - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "print(\"\\nNBoW Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc396ad-7ff6-4bd8-b9a1-3999be115799",
   "metadata": {},
   "source": [
    "### Cell 10: Initial NBoW Model Evaluation (Weighted Loss, Default 0.5 Threshold)\n",
    "Performs an initial evaluation of the NBoW model (trained with weighted loss) on the \n",
    "validation set. It calculates and prints a classification report, ROC AUC scores, and Exact Match Ratio using the default 0.5 threshold for binary predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b19c00-53f0-42a7-8498-aa6124832669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NBoW model evaluation on the validation set...\n",
      "\n",
      "--- NBoW Model: Classification Report ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.53      0.84      0.65      3013\n",
      " severe_toxic       0.22      0.90      0.35       313\n",
      "      obscene       0.53      0.87      0.66      1626\n",
      "       threat       0.06      0.88      0.11        99\n",
      "       insult       0.47      0.86      0.60      1520\n",
      "identity_hate       0.09      0.82      0.17       267\n",
      "\n",
      "    micro avg       0.38      0.85      0.53      6838\n",
      "    macro avg       0.32      0.86      0.42      6838\n",
      " weighted avg       0.48      0.85      0.60      6838\n",
      "  samples avg       0.05      0.08      0.06      6838\n",
      "\n",
      "\n",
      "--- NBoW Model: ROC AUC Score (per class and average) ---\n",
      "ROC AUC for class 'toxic': 0.9364\n",
      "ROC AUC for class 'severe_toxic': 0.9731\n",
      "ROC AUC for class 'obscene': 0.9641\n",
      "ROC AUC for class 'threat': 0.9606\n",
      "ROC AUC for class 'insult': 0.9569\n",
      "ROC AUC for class 'identity_hate': 0.9189\n",
      "Average ROC AUC (macro, ignoring NaN): 0.9517\n",
      "\n",
      "NBoW Model: Exact Match Ratio (Accuracy): 0.8379\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting NBoW model evaluation on the validation set...\")\n",
    "model_nbow.eval()\n",
    "all_true_labels_nbow = []\n",
    "all_predicted_probs_nbow = []\n",
    "all_predicted_labels_nbow = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in val_loader:\n",
    "        features = features.to(device)\n",
    "        logits = model_nbow(features)\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()\n",
    "        binary_predictions = (probabilities >= 0.5).astype(int)\n",
    "        all_true_labels_nbow.extend(labels.numpy().astype(int))\n",
    "        all_predicted_probs_nbow.extend(probabilities)\n",
    "        all_predicted_labels_nbow.extend(binary_predictions)\n",
    "\n",
    "all_true_labels_nbow_np = np.array(all_true_labels_nbow)\n",
    "all_predicted_labels_nbow_np = np.array(all_predicted_labels_nbow)\n",
    "all_predicted_probs_nbow_np = np.array(all_predicted_probs_nbow)\n",
    "\n",
    "print(\"\\n--- NBoW Model: Classification Report ---\")\n",
    "report_nbow = classification_report(all_true_labels_nbow_np, all_predicted_labels_nbow_np, target_names=label_columns, zero_division=0)\n",
    "print(report_nbow)\n",
    "\n",
    "print(\"\\n--- NBoW Model: ROC AUC Score (per class and average) ---\")\n",
    "roc_auc_per_class_nbow = []\n",
    "for i in range(all_true_labels_nbow_np.shape[1]):\n",
    "    try:\n",
    "        score = roc_auc_score(all_true_labels_nbow_np[:, i], all_predicted_probs_nbow_np[:, i])\n",
    "        print(f\"ROC AUC for class '{label_columns[i]}': {score:.4f}\")\n",
    "        roc_auc_per_class_nbow.append(score)\n",
    "    except ValueError:\n",
    "        print(f\"ROC AUC for class '{label_columns[i]}': Not computable (likely only one class present in y_true).\")\n",
    "        roc_auc_per_class_nbow.append(float('nan'))\n",
    "\n",
    "valid_roc_auc_scores_nbow = [s for s in roc_auc_per_class_nbow if not np.isnan(s)]\n",
    "if valid_roc_auc_scores_nbow:\n",
    "    print(f\"Average ROC AUC (macro, ignoring NaN): {np.mean(valid_roc_auc_scores_nbow):.4f}\")\n",
    "\n",
    "exact_match_accuracy_nbow = accuracy_score(all_true_labels_nbow_np, all_predicted_labels_nbow_np)\n",
    "print(f\"\\nNBoW Model: Exact Match Ratio (Accuracy): {exact_match_accuracy_nbow:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717e2f4-9f11-488e-9415-8a1577ccfa7b",
   "metadata": {},
   "source": [
    "## Cell 11: Optimal Threshold Tuning\n",
    "Using the probabilities predicted by the NBoW model (from Cell 10), this cell finds the optimal classification threshold for each toxicity class that maximizes its F1-score on the validation set. It then prints these optimal thresholds and a new classification report and Exact Match Ratio based on these tuned thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8fbcab-619b-4615-b6e3-0724f0502b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threshold tuning for NBoW model (trained with weighted loss)...\n",
      "Class 'toxic': Optimal Threshold = 0.72, Best F1 = 0.7237\n",
      "Class 'severe_toxic': Optimal Threshold = 0.92, Best F1 = 0.4751\n",
      "Class 'obscene': Optimal Threshold = 0.76, Best F1 = 0.7317\n",
      "Class 'threat': Optimal Threshold = 0.96, Best F1 = 0.3038\n",
      "Class 'insult': Optimal Threshold = 0.75, Best F1 = 0.6710\n",
      "Class 'identity_hate': Optimal Threshold = 0.91, Best F1 = 0.3307\n",
      "\n",
      "Optimal thresholds found for each class:\n",
      "  toxic: 0.72\n",
      "  severe_toxic: 0.92\n",
      "  obscene: 0.76\n",
      "  threat: 0.96\n",
      "  insult: 0.75\n",
      "  identity_hate: 0.91\n",
      "\n",
      "--- Classification Report (with Tuned Thresholds) ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.71      0.74      0.72      3013\n",
      " severe_toxic       0.38      0.64      0.48       313\n",
      "      obscene       0.69      0.77      0.73      1626\n",
      "       threat       0.26      0.36      0.30        99\n",
      "       insult       0.61      0.74      0.67      1520\n",
      "identity_hate       0.26      0.46      0.33       267\n",
      "\n",
      "    micro avg       0.63      0.73      0.67      6838\n",
      "    macro avg       0.49      0.62      0.54      6838\n",
      " weighted avg       0.65      0.73      0.68      6838\n",
      "  samples avg       0.06      0.06      0.06      6838\n",
      "\n",
      "\n",
      "NBoW Model: Exact Match Ratio (Accuracy) with Tuned Thresholds: 0.8982\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score \n",
    "\n",
    "print(\"Starting threshold tuning for NBoW model (trained with weighted loss)...\")\n",
    "\n",
    "optimal_thresholds = {}\n",
    "best_f1_scores = {}\n",
    "\n",
    "threshold_candidates = np.arange(0.01, 1.00, 0.01)\n",
    "\n",
    "for i, class_name in enumerate(label_columns):\n",
    "    best_threshold_for_class = 0.5 \n",
    "    best_f1_for_class = 0.0\n",
    "    \n",
    "    true_labels_for_class = all_true_labels_nbow_np[:, i]\n",
    "    pred_probs_for_class = all_predicted_probs_nbow_np[:, i]\n",
    "    \n",
    "    if np.sum(true_labels_for_class) == 0:\n",
    "        print(f\"Class '{class_name}': No positive samples in validation set. Skipping threshold tuning, using default 0.5.\")\n",
    "        optimal_thresholds[class_name] = 0.5\n",
    "        temp_preds = (pred_probs_for_class >= 0.5).astype(int)\n",
    "        best_f1_for_class = f1_score(true_labels_for_class, temp_preds, zero_division=0)\n",
    "        best_f1_scores[class_name] = best_f1_for_class\n",
    "        continue\n",
    "\n",
    "    for threshold in threshold_candidates:\n",
    "        binary_predictions_for_class = (pred_probs_for_class >= threshold).astype(int)\n",
    "        current_f1 = f1_score(true_labels_for_class, binary_predictions_for_class, average='binary', zero_division=0)\n",
    "        \n",
    "        if current_f1 > best_f1_for_class:\n",
    "            best_f1_for_class = current_f1\n",
    "            best_threshold_for_class = threshold\n",
    "            \n",
    "    optimal_thresholds[class_name] = best_threshold_for_class\n",
    "    best_f1_scores[class_name] = best_f1_for_class\n",
    "    print(f\"Class '{class_name}': Optimal Threshold = {best_threshold_for_class:.2f}, Best F1 = {best_f1_for_class:.4f}\")\n",
    "\n",
    "print(\"\\nOptimal thresholds found for each class:\")\n",
    "for class_name, thresh in optimal_thresholds.items():\n",
    "    print(f\"  {class_name}: {thresh:.2f}\")\n",
    "\n",
    "all_predicted_labels_tuned_np = np.zeros_like(all_predicted_probs_nbow_np, dtype=int)\n",
    "for i, class_name in enumerate(label_columns):\n",
    "    threshold = optimal_thresholds[class_name]\n",
    "    all_predicted_labels_tuned_np[:, i] = (all_predicted_probs_nbow_np[:, i] >= threshold).astype(int)\n",
    "\n",
    "print(\"\\n--- Classification Report (with Tuned Thresholds) ---\")\n",
    "report_tuned = classification_report(all_true_labels_nbow_np, all_predicted_labels_tuned_np, target_names=label_columns, zero_division=0)\n",
    "print(report_tuned)\n",
    "exact_match_accuracy_tuned = accuracy_score(all_true_labels_nbow_np, all_predicted_labels_tuned_np)\n",
    "print(f\"\\nNBoW Model: Exact Match Ratio (Accuracy) with Tuned Thresholds: {exact_match_accuracy_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e7422-d1a8-4d55-aa5f-602670d8d7b6",
   "metadata": {},
   "source": [
    "### Cell 12: Save NBoW Model and Artifacts\n",
    "This cell saves the trained NBoW model's state dictionary and the vocab_to_int dictionary along with SEQ_LENGTH for future use (e.g., in an API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccc46f72-eba4-41fe-a847-3d89fec69124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBoW Model state saved to: ../model_artifacts/nbow_model_state.pth\n",
      "NBoW Vocabulary, SEQ_LENGTH, label_columns, and OPTIMAL THRESHOLDS saved to: ../model_artifacts/nbow_vocab_config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "\n",
    "\n",
    "ARTIFACTS_DIR = '../model_artifacts' \n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# Используем оригинальные имена файлов, которые ожидает API\n",
    "MODEL_STATE_FILENAME_IN_ARTIFACTS = 'nbow_model_state.pth'\n",
    "VOCAB_CONFIG_FILENAME_IN_ARTIFACTS = 'nbow_vocab_config.json' # <--- ИСПРАВЛЕНО ИМЯ ФАЙЛА\n",
    "\n",
    "model_state_path = os.path.join(ARTIFACTS_DIR, MODEL_STATE_FILENAME_IN_ARTIFACTS)\n",
    "vocab_config_path = os.path.join(ARTIFACTS_DIR, VOCAB_CONFIG_FILENAME_IN_ARTIFACTS)\n",
    "\n",
    "torch.save(model_nbow.state_dict(), model_state_path)\n",
    "print(f\"NBoW Model state saved to: {model_state_path}\")\n",
    "\n",
    "full_config_to_save = {\n",
    "    'vocab_to_int': vocab_to_int,\n",
    "    'SEQ_LENGTH': SEQ_LENGTH,\n",
    "    'label_columns': label_columns,\n",
    "    'optimal_thresholds': optimal_thresholds\n",
    "}\n",
    "with open(vocab_config_path, 'w') as f:\n",
    "    json.dump(full_config_to_save, f, ensure_ascii=False, indent=4)\n",
    "print(f\"NBoW Vocabulary, SEQ_LENGTH, label_columns, and OPTIMAL THRESHOLDS saved to: {vocab_config_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
